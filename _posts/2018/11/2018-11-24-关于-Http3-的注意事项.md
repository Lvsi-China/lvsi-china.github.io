---
layout:     post
title:      【译】关于 Http/3 的注意事项
subtitle:   HTTP/3标准化
date:       2018-11-24
author:     Grape
header-img: 
catalog: true
tags:
    - HTTP
---

## 【译】关于 Http/3 的注意事项

> 原文 [《Some notes about HTTP/3》](https://blog.erratasec.com/2018/11/some-notes-about-http3.html#.W_idYlUzbDe)<br/>
> 译者：[Grape](https://github.com/Lvsi-China)

Http/3很快就要标准化了，作为一个古老的协议，我想我应该对此写些评注。

谷歌同时拥有着世界上最流行的浏览器（Chrome）和两个最流行的网站（google.com, youtube.com）， 因此它们都会控制着未来网络协议的发展，它们的第一次更新叫做 SPDY(读作 speedy)， 最终作为了HTTP或HTTP/2的标准版本。第二次更新叫做 QUIC(读作 quick)，正在作为HTTP/3的标准版本。

SPDY（HTTP/2）已经被主流的浏览器（Chrome, Firefox, Edge, Safari）和主流服务器（Apache, Nginx, IIS, CloudFlare）所支持。也被许多最流行的网站支持（不只是 Google的产品），即使你好像从没见过它（使用Wireshark 或 tcpdump进行网络嗅探）。因为它总是使用SSL加密，虽然标准允许HTTP/2通过TCP传输原始数据，但是所有的实现都是通过SSL使用它的。

关于标准有一个重要解释，网络之外，标准通常是法律上的，由政府运营，通过把相关利益持有者聚集起来商讨出结果，然后使用法律去强制使大众接受。但在互联网上，部分开发者首先实现了标准，然后如果其他的开发者也喜欢它的话，便也会开始使用。标准通常就是事实，RFC(请求意见稿)是针对于在网络上已经使用良好的部分撰写的，记录了正在使用的东西。浏览器/服务器采用SPDY不是因为它是标准化的，只是因为主要参与者都是以它作为标准。QUIC也是如此：它被标准化为HTTP/3的事实仅反映了它已被使用，而不是一个因为标准化了所以才可被投入使用的里程碑。

QUIC其实更多的是一个新版本的TCP（难到叫做 TCP/2 ??）而不是新版本的HTTP（HTTP / 3）。 它并没有真正改变HTTP/2的工作方式，而是改变了传输的工作方式。 因此，我下面的评注会侧重于传输问题而不是HTTP问题。

主要的特性是更快的连接设置和延迟，TCP需要在建立连接之前发送多个往返数据包，SSL也需要在加密建立之前发生多个往返数据包，如果有网络延迟，例如当人们ping时使用的是星互联网网，建立连接就会需要相当长的时间，通过减少往返次数，连接可以更快的建立起来，因此当你点击一个链接的时候，资源就会立刻的展示出来。

下一个特性是带宽，在一条网络连接的源和目标之间总是有带宽限制的，几乎都是由于拥塞，双方都需要找到一个方便以合适速率发送数据包的的速度。发送数据包速度太快，不会提高传输效率，反而部分数据包将会被丢弃，导致其他人发送的数据包也拥塞。发送数据包太慢则意味着没有最佳的使用网络。

传统的HTTP在这方面做的很不好，使用单条的TCP连接是不适用与HTTP的。因为与网站的交互需要同时传输多个不同的内容，因此浏览器打开了与Web服务器的通信的多条TCP连接（通常为6条连接）。但是，这会打破预估带宽，因为每个TCP连接都会尝试独立完成，就像其他连接不存在一样。SPDY通过其多路复用功能解决了这个问题，该功能将浏览器/服务器之间的多个交互只与单个带宽共同预估。

QUIC扩展了这种多路复用，使得处理浏览器/服务器之间的多个交互变得更加容易，各个交互之间互不干扰，但使用单个带宽预估，从用户的角度来看，这将使交互更加顺畅，同时减少了通过路由器时的拥塞。

现在谈谈用户模式堆栈。TCP的问题的突出表现于在服务器上时，TCP的连接是由操作系统内核处理的，而服务本身在用户态中运行。 跨内核/用户态边会导致性能问题。 跟踪大量TCP连接会引起可伸缩性问题。 有些人尝试将服务加入内核，以避免转换。这是一个糟糕的举措因为它破坏了操作系统的稳定性。 我自己的解决方案是使用BlackICE IPS和masscan，就是使用硬件的用户态驱动程序，把接收到的数据包从网络芯片直接传送到用户态进程，绕过内核(参见 PoC GTFO #15)，使用自定义的TCP堆栈。 近年来，DPDK套件已经流行起来。

但是，从TCP迁移到UDP可以在没有用户态驱动程序的情况下获得相同的性能。你可以调用```recvmmsg()```一次接收一堆UDP数据包，而不是调用众所周知的```recv()```函数来一次接收一个数据包。

在我自己的测试中，使用典型的```recv()```函数被大约限制为500,000 UDP /秒，但使用```recvmmsg()```和一些其他的优化(使用RSS的多核)，可以在四核服务器上于低位达到5,000,000 UDP包/秒。 由于每个核心的扩展性很好，因此迁移到具有64个核心的强大服务器上应该可以进一步改进。

顺便提一下，“RSS”是网络硬件的一个功能，它将传入的数据包分成多个接收队列。多核可扩展性的最大问题是无论何时两个CPU核心需要同时读取/修改同一个东西，因此共享相同的UDP数据包队列成为最大的瓶颈。因此，首先英特尔和其他以太网供应商添加了RSS，为每个核心提供了自己的非共享数据包队列。 Linux和其他操作系统升级UDP以支持单个套接字（SO_REUSEPORT）的多个文件描述符来处理多个队列。现在，QUIC使用这些改进，允许每个核心管理自己的UDP数据包流，而没有与其他CPU核心共享内容的可扩展性问题。我之所以提到这一点，是因为我亲自与英特尔硬件工程师讨论过在2000年有多个数据包队列问题。这是一个常见的问题，也是一个明显的解决方案。有趣的是，它在过去的二十年里不断改进，直到以HTTP/3的推出达到最高点。如果没有网络硬件中的RSS，QUIC就不太可能成为标准。

QUIC的另一个很酷的解决方案是移动支持。 当你将笔记本电脑移动到不同的WiFI网络或随手机移动时，你的IP地址可能会发生变化。 操作系统和协议不能正常关闭旧连接并打开新连接。 但是，对于QUIC，连接的标识符不是“套接字”（源/目标端口/地址协议 的组合）的传统概念，而是分配给连接的64位标识符。

这意味着，当你四处移动时，即使IP地址发生变化，你也可以继续获得从YouTube的不间断地流式传输，或者继续视频电话，而不会被丢弃。 几十年来，互联网工程师一直在努力解决“移动IP”问题，试图提出一个可行的解决方案。 他们专注于端到端原则，以便在你四处移动时以某种方式保持一个恒定的IP地址，这不是一个实际的解决方案。 很高兴看到QUIC/HTTP/3最终通过现实世界中的工作方案来解决这个问题。

如何使用这种新的传输？ 几十年来，网络编程的标准一直是传输层API，称为“套接字”。 你可以在代码中调用```recv()```等函数来接收数据包。 使用QUIC/HTTP/3，我们不再有操作系统传输层API。 相反，它是一个更高层的功能，你可以在go编程语言中使用，或者在OpenResty nginx Web服务器中使用Lua。

我之所以提到这一点，是因为你对OSI模型的教育中缺少一点，它最初设想每个人都在编写应用层（7）API而不是传输层（4）API。 应该有像应用程序服务元素之类的东西，它们可以为不同应用程序以标准方式处理文件传输和消息传递等。 我认为人们越来越多地转向这种模式，特别在谷歌的go语言，QUIC，protobufs等驱动之下。

我之所以提到这一点，是因为谷歌和微软之间的对比。 微软拥有一个流行的操作系统，因此它的创新是由它在该操作系统中的功能所驱动的。 谷歌的创新是由它可以放在操作系统之上所驱动的。 然后有Facebook和Amazon他们自己必须在谷歌提供给它们的堆栈基础之上（或之外）进行创新。 按顺序世界排名前五的公司是Apple-Google-Microsoft-Amazon-Facebook，因此每个公司推动创新都很重要。

结论

当TCP在20世纪70年代创建时，它是崇高的。 它处理的事情，如拥塞，比竞争协议要好得多。 对比人们宣布IPv4时却没有预料到需要IP地址的将超过40亿，它所预计的现代互联网要比70年代和80年代的竞争设计要好得多。 从IPv4到IPv6的升级在很大程度上保持了IP的优势。 从TCP到QUIC的升级同样基于TCP的优点，但将其扩展到现代需求。 实际上，令人惊讶的是，TCP已经持续了这么长时间，这很好，没有升级。
