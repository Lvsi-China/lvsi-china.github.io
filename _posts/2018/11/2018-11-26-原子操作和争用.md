---
layout:     post
title:      【译】原子操作和争用
subtitle:   总线锁 & 缓存行
date:       2018-11-26
author:     Grape
header-img: 
catalog: true
tags:
    - 原子操作
---

## 【译】原子操作和争用

> 翻译文章来自 [《Atomic operations and contention》](https://fgiesen.wordpress.com/2014/08/18/atomics-and-contention/)<br>
> 译者：[Grape](https://github.com/WGrape)

上周，我们介绍了缓存一致性的基本工作原理，今天，我们谈谈在缓存一致的基础之上构建一个可用的系统所需要的一些原语，以及它是如何工作的。

## 原子性和原子操作

所有这一切的关键都是原子操作，这与物理学中的原子是不相干的，和“原子”这个词的根源有关，古希腊语 “ἄτομος” (atomos, “不可分割”)。一个原子操作无法再分成更小的子操作，可能看起来是出于系统中其他核心需要的目的。要理解为什么这很重要，可以考虑这种情况：当2个核心都尝试以完全相同的方式去自增一个counter计数器时会发生什么，与之等效的是C语句中的自增语句： ```counter++```。

<img src="/img/posts/2018/11-26/1.png">

在编译的代码中，```counter++``` 这个单一的操作变成了 ```load```读取操作 + ```register```自增操作 + ```store```存储操作（这里写的是C式的伪代码）。这3个步骤是不同的并且会顺序执行（注意，在微架构级别x86 上也是如此，即使指令集架构上已经具有 read-modify-write 指令，如```add [memory], value```指令）。并且由于拆分为了多个循环，是可能出现在核心1已经读了```counter```并且开始自增它的时候，核心2在```counter```被核心1自增之前```read```读取到了```counter```。结果就是，即是两个核心都执行了自增```counter```的代码，但是```counter```最后的值只被增加了1次，其中的一次自增操作由于被覆盖就丢失了。

这个问题正是原子操作需要防止的，如果我们使用一个不是常规自增的原子操作（或者更简单的说是```add```操作），运行着的核心必须确保上述的3个连续的操作(```load``` + ```add``` + ```store```)看起来像是一个操作一样，这就是原子操作。当一个核心正在执行```increment```自增操作的时候，不允许其他的核心“窥视”。

## 如何实现原子操作

现在的问题是，如何做到？从概念上讲，最简单的方法是使用锁机制：在任何时间点，都只允许1个核心执行原子操作，从1个核心开始执行原子操作的时候开始锁定，当操作执行完的时候离开。这是 X86 ```LOCK``` 前缀最初使用的方法(我简化了操作，大概是这样而已)。比如，在一个原子操作中，Lock锁会在总线上传递一个消息：好吧，大家都从总线上往后退一些(对于我们来说，这意味着“停止执行内存操作”)。然后发送那个消息的核心会等待其他的核心结束当前正在执行的内存操作，之后它们会确认锁定。只有在其他的核心都确认锁定之后，这个核心才能继续工作。最后，一旦锁被释放，它再次向总线上的每一个核心发送消息：现在你们可以恢复在总线上请求了。

这很有效，但是也及其的低效， X86 CPU 依然支持这个操作(或者是等效的操作)，但是只作为一个紧急方案，当all-else-failed回退时，他们需要回退，因为x86ISA允许非常可疑的构造，例如跨越多个缓存行的未对齐原子操作，以实现向后兼容性。其他体系结构通常不允许对非自然对齐的值进行原子操作，也不允许对“太大”的值进行原子操作。这些约束保证单个原子操作始终在单个高速缓存行中进行。一旦我们有了这个，我们就处于良好状态：正如我们上次讨论缓存一致性协议时所看到的那样，核心间通信无论如何都会以高速缓存行粒度同步内存，所以原则上我们可以对单个缓存行进行复杂的修改，然后通过推送新的缓存行去发布所有更改。此外，MESI状态机具有两种状态（M和E，“修改”和“独占”），保证一个核心独占所有权 - 而高速缓存行是专有的，没有其他内核可以“窥视”。我们可以用它代替我们的锁定协议。

所以这里有一个妙处：在MESI（或派生）系统中，我们需要做的就是确保触摸单个缓存行的操作是原子的a）确保我们发出正确的内存屏障，以便正确地排序内存操作参考周围的代码（参见上一篇文章），b）在我们读取任何内容之前获取高速缓存行的独占所有权，c）如果我们在整个原子操作期间拥有独占所有权，则只回写结果。这保证了没有其他核心看到任何半成品数据。有多种方法可以完成c）。例如，我们可以构建硬件，在一个总线时钟周期内完成一组有限的原子操作; 如果我们在一个周期的开始就拥有我们的缓存行的独占所有权，我们可以在它结束时获得我们的修改数据。由于高速缓存行不可能在一个周期内“转手”，这足够快。根据总线协议，我们也可以开始玩游戏，我们立即响应一致性消息，但如果我们处于原子操作的中间，可能会稍晚发送数据。最后，我们可以决定不按时间玩游戏; 相反，我们直接实现步骤b）和c）：任何用于原子操作的高速缓存行都被“监视”，如果某个其他核心在原子操作完成之前查看我们的高速缓存行，我们需要重新开始。这就是导致这种情况的原因 最后，我们可以决定不按时间玩游戏; 相反，我们直接实现步骤b）和c）：任何用于原子操作的高速缓存行都被“监视”，如果某个其他核心在原子操作完成之前查看我们的高速缓存行，我们需要重新开始。这就是导致这种情况的原因 最后，我们可以决定不按时间玩游戏; 相反，我们直接实现步骤b）和c）：任何用于原子操作的高速缓存行都被“监视”，如果某个其他核心在原子操作完成之前查看我们的高速缓存行，我们需要重新开始。这就是导致这种情况的原因大多数RISC CPU中存在的加载链接/存储条件（LL / SC）操作。

顺便说一下，在总线端（以及因此到其他核心），正确对齐的原子操作看起来与正常的内存更新没有任何不同。同样，所有处理都是核心的内部处理; 其他内核既不知道也不关心内存是否由内存屏障或松散存储区域中的原子比较和交换操作更新。

这一切听起来既简单又简单，从概念上讲，它就是细节中的魔鬼。坏消息是，如果你是一名CPU架构师，这个过程的每一个细节都至关重要; 你的内存操作的内部实现需要避免饥饿（每个想要获得对高速缓存行的独占访问的核心应该能够这样做，最终，无论其他内核在做什么），并确保它可以实现某些基本的原子操作没有死锁或活锁。这听起来很明显，但这些保证不是自动处理原子操作或LL / SC等低级原语。这个东西很难做到，CPU需要有一个不仅正确的实现，它还需要快速的“典型案​​例”（无论它们是什么）。好消息是，如果你不是在设计CPU的公司工作，这不是你的问题，你可以放心，其他人已经考虑过这一点，由一群验证工程师提供支持，努力寻找打破它的测试用例。

> 声明：由于事情繁多，精力有限，下面的翻译暂时被搁置，只能等待下次有时间时补上。 因此暂时先用 Google 翻译代替，抱歉。<br/>
> 希望有人能够不吝啬的做出贡献，因为不仅是帮助别人。

## 内存操作的成本
回到SW方面，我们假设我们采用的是典型的CPU架构，并且在多个内核上运行代码。在该环境中内存操作的成本是多少？它分为几个部分：

执行。执行内存操作不是免费的。假设现在只有一个核心处于活动状态并运行单线程代码; 即使这样，内存访问仍然很复杂。程序处理虚拟地址，但是一致的高速缓存和存储器总线通常仅处理物理存储器地址。因此，每个内存操作首先从虚拟到物理地址转换开始（这些转换本身缓存在通常称为Translation Lookaside Buffer或TLB的内容中）。如果你运气不好，那个虚拟地址当前没有映射到物理内存，需要从存储中引入; 每当发生这种情况时，操作系统将在活动核心上安排另一个线程一段时间，因为IO在处理器方面需要很长时间。但是我们假设这不会发生。

在已知物理地址的情况下，操作开始通过内存层次结构。例如，要完成内存加载，通常需要首先将相关数据引入L1缓存。如果它还没有，那么这可能是一个多步骤的过程 - 在最坏的情况下 - 涉及真正的内存访问，然后填充相关缓存行的所有中间缓存级别。由于内存访问模式较差（即不是很好的本地化），等待缓存级别的填充是CPU核心花费时间的主要方式之一。但就目前而言，我们假设这种情况不会发生（太频繁）。

那么如果一切顺利，我们可以多快地运行内存操作？结果很快，结果很快。通常每个时钟周期至少完成一次操作（加载/存储），通常比这更多。合理的缓存友好代码将在单个3GHz内核上每秒完成数十亿次内存操作。

内存障碍和原子读 - 修改 - 写操作。对于下一步，让我们假设我们正在运行用于多线程操作的代码，但我们仍然只在一个核心上执行此操作。结果，我们现在将看到内存障碍和原子操作，但没有来自另一个核心的实际干扰; 让我们假设所有相关的缓存行都已由我们自己的核心独占。在那种情况下，使用原子整数加法更新引用计数有多贵？

那么，这真的取决于CPU核心。通常，具有积极的存储器操作重新排序的微架构比仅具有轻微重新排序或有序执行存储器操作的微架构具有更昂贵的存储器屏障和原子操作。例如，LOCK INC [mem]在英特尔凌动核心上使用递增引用计数（有序设计）与常规核心成本基本相同INC [mem]指令，以及更复杂的原子操作，如交换或交换 - 添加结束成本约为“香草”内存读 - 修改 - 写指令的2倍到3倍。相比之下，在Intel和AMD的无序x86桌面部件上，原子增量大约是非原子版本的10倍-25倍; 这是确保正确记忆的成本。再说一遍，重申：这仍然是执行单线程的代码。目前还没有实际的跨核通信; 这个额外的成本纯粹在单个核心内产生，使代码对于多核执行是安全的。

总线流量和缓存一致性。一定比例的内存访问实际上错过了缓存并直接进入内存; 一旦一段时间没有被使用的缓存行被驱逐，我们就会开始回写。所有这些事件都会导致总线流量（和内存流量）。总线和内存带宽是有限的资源; 当我们开始使他们的能力饱和时，事情开始变慢。

此外，一旦我们切换到在多个内核上运行我们程序的多个线程，我们实际上开始获得缓存一致性流量，因为内核不断地同步它们各自的内存视图。如果每个线程都在自己独立的内存区域上运行，那么这并没有太大作用; 如果给定的内存区域仅由一个核心使用，那么就没有共享，并且获得对应的一个缓存行的独占所有权很容易，并且不会在其他地方引起任何失效。

相反，如果两个或多个内核经常访问相同的高速缓存行，则需要保持这些高速缓存行同步。对其中一个缓存行的更新需要独占所有权，这意味着所有其他核心需要首先使其缓存行的副本无效。结果，下一次该高速缓存行被另一个核访问时，其内容需要通过总线发送。因此，我们得到额外的缓存未命中（在远程核心上）和额外的总线流量。这种多核攻击正在定期更新的缓存行的现象称为“缓存（行）争用”，它可能是在共享内存环境中进行并行代码爬行的最简单方法。

## 缓存行争用
为了获得缓存行争用，我们需要经常访问同一缓存行的多个核心，其中至少有一些常规访问是写入。私有数据（仅由一个线程访问的缓存行）绝不是问题; 既不是不可变数据（一次编写，直到其生命周期结束时才被修改）。令人困惑的是共享和可变的数据：这样做需要大量的通信来维持一致的（根据内存模型的约束）内核之间的内存视图，并且通信成本很高 - 并且只是不断增加更多的政党参与其中。

我们说话要贵多少钱？几个星期前我写了一个测试（针对x86 / Windows）。该测试决不是用户友好的或易于阅读的，它假定具有同时多线程或类似拓扑的四核CPU具有至少8个逻辑处理器。以下是它的要点：如上所述，用原子“添加”操作替换内存中值的读 - 修改 - 写入通常使其大约10x-25x一样昂贵（多少完全取决于微架构） 。如果你需要一个经验法则，只需假设大约10倍（对于费米估计来说足够好）。

然而，一旦有第二个核心读取缓​​存行，成本就会爆炸。如果有另一个核心在一个紧凑的循环缓存行产生大量读取流量，原子添加变得更加昂贵- 很多更昂贵的：通常情况下，4倍至6倍多（这是在〜10倍命中的顶部我们从使用原子添加开头！）。如果有更多的读者，这个成本只会增加，如果还有其他作家，这个成本会更高。现在，请不要将这些价值作为福音; 这是一个完全合成的基准测试，没有任何用处。一致性流量的实际成本在很大程度上取决于上下文。我想在这里做的就是让你对一致性流量和沟通的成本有一个非常粗略的感觉（即：它不可忽略不计）。

有些沟通实际上并不是必需的。例如，因为高速缓存一致性是以高速缓存行粒度跟踪的，所以可以使大量的伪造一致性流量变得简单，因为不同类型的数据 - 不可变，私有和共享 - 在同一个高速缓存行中混合（或类似地，因为一个高速缓存line包含多个线程的私有数据）。这称为“ 虚假共享 ”。幸运的是，使用分析器很容易找到这种问题，并且通过重新排序内存中的数据也可以相对简单地修复（可能在添加填充以确保两种不同类型的数据不会在同一缓存中结束时） （或完全删除一些违规数据）。我的老帖子“ Cores不喜欢分享 ”就是一个例子。

在此过程之后剩下的是“真实”争用 - 争用对共享数据的访问。这包括实际共享的可变数据结构和某些类型的元数据，例如锁和其他同步对象。这究竟有多好，取决于内存中数据的精确布局，以及用于访问它的操作。

通常，获得可扩展的多处理器代码的方法是尽可能避免争用，并使任何争用仍然快速通过 - 按此顺序。在这方面做得不错，重要的是要知道缓存一致性是如何工作的（无论如何），核心交换什么样的消息以保持记忆的一致性，以及何时发生这种一致性流量。现在我们已经涵盖了这些基础知识，我们可以查看更高级别的堆栈。这篇文章已经足够长了，但在下一篇文章中，我打算看看锁和无锁数据结构，并讨论一些权衡。在那之前，要小心！